name: cinepulse

# ---------- shared anchors ----------
x-app-env: &app_env
  env_file:
    - ../.env
  environment: &env_defaults
    TZ: ${TZ:-UTC}
    ENV: ${ENV:-prod}
    LANG: ${LANG:-C.UTF-8}
    PYTHONUNBUFFERED: "1"
    DATABASE_URL: ${DATABASE_URL:-postgresql+psycopg://postgres:postgres@db:5432/cinepulse}
    REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
    TMDB_API_KEY: ${TMDB_API_KEY:-}
    FEED_KEY: ${FEED_KEY:-feed:items}
    SOURCES_FILE: /app/source.yml
    # ---- API pagination + rate limits ----
    BATCH_SIZE: ${BATCH_SIZE:-200}
    RL_FEED_PER_MIN: ${RL_FEED_PER_MIN:-120}
    RL_SEARCH_PER_MIN: ${RL_SEARCH_PER_MIN:-90}
    RL_STORY_PER_MIN: ${RL_STORY_PER_MIN:-240}
    # ---- summarization knobs ----
    SUMMARY_TARGET_WORDS: ${SUMMARY_TARGET_WORDS:-85}
    SUMMARY_MIN_WORDS: ${SUMMARY_MIN_WORDS:-60}
    SUMMARY_MAX_WORDS: ${SUMMARY_MAX_WORDS:-110}
    SUMMARY_PASSTHROUGH_MIN_CHARS: ${SUMMARY_PASSTHROUGH_MIN_CHARS:-220}
    SUMMARY_PASSTHROUGH_MAX_CHARS: ${SUMMARY_PASSTHROUGH_MAX_CHARS:-1200}
    SUMMARY_PASSTHROUGH_MIN_SENTENCES: ${SUMMARY_PASSTHROUGH_MIN_SENTENCES:-2}
    FEED_ALLOWED_INDUSTRIES: ${FEED_ALLOWED_INDUSTRIES:-bollywood}

x-logging: &default_logging
  driver: json-file
  options:
    max-size: "10m"
    max-file: "5"

x-hardened: &hardened
  read_only: true
  tmpfs:
    - /tmp
  security_opt:
    - no-new-privileges:true
  cap_drop:
    - ALL
  ulimits:
    nofile:
      soft: 4096
      hard: 8192

# ---------- networking / storage ----------
networks:
  app:
    driver: bridge

volumes:
  dbdata: {}
  redisdata: {}

services:
  db:
    image: postgres:16
    restart: unless-stopped
    environment:
      POSTGRES_DB: cinepulse
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - dbdata:/var/lib/postgresql/data
    networks:
      - app
    logging: *default_logging
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d cinepulse"]
      interval: 10s
      timeout: 5s
      retries: 5
    profiles: ["db"]   # optional for free tier (start only if needed)

  redis:
    image: redis:7-alpine
    restart: unless-stopped
    command: redis-server --appendonly yes
    volumes:
      - redisdata:/data
    networks:
      - app
    logging: *default_logging
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  api:
    <<: [*app_env, *hardened]
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: api
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
      # db is optional; uncomment if API needs DB:
      # db:
      #   condition: service_healthy
    environment:
      <<: *env_defaults
      CORS_ORIGINS: ${CORS_ORIGINS:-*}
      MAX_SCAN: ${MAX_SCAN:-400}
    volumes:
      - ./source.yml:/app/source.yml:ro
    networks:
      - app
    ports:
      - "127.0.0.1:18000:8000"
    command: >
      gunicorn -k uvicorn.workers.UvicornWorker -w ${API_WORKERS:-1}
      -b 0.0.0.0:8000 apps.api.app.main:app
      --timeout 30 --keep-alive 5
      --max-requests 800 --max-requests-jitter 80
    healthcheck:
      test:
        - CMD-SHELL
        - |
          python - <<'PY'
          import json,sys,urllib.request
          try:
              r=urllib.request.urlopen('http://localhost:8000/health',timeout=3)
              j=json.loads(r.read().decode('utf-8'))
              ok = (r.status==200) and (j.get('status')=='ok')
              sys.exit(0 if ok else 1)
          except Exception:
              sys.exit(1)
          PY
      interval: 20s
      timeout: 5s
      retries: 5
    logging: *default_logging
    cpus: "0.25"
    mem_limit: "128m"

  worker:
    <<: [*app_env, *hardened]
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: worker
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./source.yml:/app/source.yml:ro
    networks:
      - app
    command: >
      sh -lc 'rq worker -u "${REDIS_URL:-redis://redis:6379/0}" events'
    healthcheck:
      test:
        - CMD-SHELL
        - |
          python - <<'PY'
          import os,sys
          from redis import from_url
          try:
              from_url(os.getenv('REDIS_URL','redis://redis:6379/0')).ping()
              sys.exit(0)
          except Exception:
              sys.exit(1)
          PY
      interval: 25s
      timeout: 5s
      retries: 5
    logging: *default_logging
    cpus: "0.25"
    mem_limit: "128m"

  # --- PUSH ingestion (preferred on free tier): WebSub for YouTube / RSS ---
  webhooks:
    <<: *hardened
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: webhooks
    restart: unless-stopped
    environment:
      <<: *env_defaults
      PUBLIC_BASE_URL: ${PUBLIC_BASE_URL:-}        # e.g. https://your-domain
      AUTO_SUBSCRIBE_ON_START: ${AUTO_SUBSCRIBE_ON_START:-1}
      USE_SOURCES_FILE: "1"
      SOURCES_FILE: /app/source.yml
      WEBHOOK_LEASE_SEC: ${WEBHOOK_LEASE_SEC:-86400}
      YT_PULL_WINDOW_HOURS: ${YT_PULL_WINDOW_HOURS:-72}
      RSS_PULL_WINDOW_HOURS: ${RSS_PULL_WINDOW_HOURS:-48}
      WEBHOOK_SHARED_SECRET: ${WEBHOOK_SHARED_SECRET:-}
    depends_on:
      redis:
        condition: service_healthy
    volumes:
      - ./source.yml:/app/source.yml:ro
    networks:
      - app
    ports:
      - "127.0.0.1:18200:8000"
    command: >
      gunicorn -k uvicorn.workers.UvicornWorker -w ${WEBHOOK_WORKERS:-1}
      -b 0.0.0.0:8000 apps.webhooks.main:app
      --timeout 30 --keep-alive 5
      --max-requests 800 --max-requests-jitter 80
    healthcheck:
      test:
        - CMD-SHELL
        - |
          python - <<'PY'
          import urllib.request,sys
          try:
              r=urllib.request.urlopen('http://localhost:8000/healthz',timeout=3)
              sys.exit(0 if r.status==200 else 1)
          except Exception:
              sys.exit(1)
          PY
      interval: 25s
      timeout: 5s
      retries: 5
    logging: *default_logging
    cpus: "0.20"
    mem_limit: "96m"

  # --- Optional polling scheduler (disabled by default; launch with --profile poller) ---
  scheduler:
    <<: [*app_env, *hardened]
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: scheduler
    restart: unless-stopped
    depends_on:
      redis:
        condition: service_healthy
    environment:
      <<: *env_defaults
      POLL_INTERVAL_MIN: ${POLL_INTERVAL_MIN:-120}
      PUBLISHED_AFTER_HOURS: ${PUBLISHED_AFTER_HOURS:-72}
      POLL_SPREAD_SEC: ${POLL_SPREAD_SEC:-2.0}
      POLL_JITTER_SEC: ${POLL_JITTER_SEC:-10}
      ONE_SHOT: ${ONE_SHOT:-}
      YT_MAX_ITEMS: ${YT_MAX_ITEMS:-20}
      RSS_MAX_ITEMS: ${RSS_MAX_ITEMS:-100}
      USE_SOURCES_FILE: "1"
      SOURCES_FILE: /app/source.yml
    volumes:
      - ./source.yml:/app/source.yml:ro
    networks:
      - app
    command: python -m apps.scheduler.main
    healthcheck:
      test:
        - CMD-SHELL
        - |
          python - <<'PY'
          import os,sys
          from redis import from_url
          try:
              from_url(os.getenv('REDIS_URL','redis://redis:6379/0')).ping()
              sys.exit(0)
          except Exception:
              sys.exit(1)
          PY
      interval: 30s
      timeout: 5s
      retries: 5
    logging: *default_logging
    cpus: "0.20"
    mem_limit: "96m"
    profiles: ["poller"]

  # --- Renderer (optional) ---
  renderer:
    <<: *hardened
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: renderer
    restart: unless-stopped
    networks:
      - app
    ports:
      - "127.0.0.1:18100:8000"
    healthcheck:
      test:
        - CMD-SHELL
        - |
          python - <<'PY'
          import urllib.request,sys
          try:
              r=urllib.request.urlopen('http://localhost:8000/health',timeout=3)
              sys.exit(0 if r.status==200 else 1)
          except Exception:
              sys.exit(1)
          PY
      interval: 25s
      timeout: 5s
      retries: 5
    logging: *default_logging
    cpus: "0.20"
    mem_limit: "96m"
    profiles: ["renderer"]
