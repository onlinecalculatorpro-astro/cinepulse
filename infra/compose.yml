# =============================================================================
# CinePulse Ingestion / Delivery Stack
#
# RUNTIME DATA FLOW (end-to-end)
#
#   ┌───────────────────────────────────────────────────────────────────┐
#   │  scheduler + webhooks                                            │
#   │    - scheduler: periodic poll of sources                        │
#   │        * reads infra/source.yml                                  │
#   │        * merges all vertical configs listed in include_verticals │
#   │        * enqueues poll work into RQ queue "events"               │
#   │    - webhooks: on-demand / push-trigger polling (YouTube WebSub, │
#   │      RSS WebSub), also enqueues into "events"                    │
#   └───────────────────────────────────────────────────────────────────┘
#                                   │
#                                   ▼
#   ┌───────────────────────────────────────────────────────────────────┐
#   │  workers (rq worker "events")                                     │
#   │    - fetch raw item (RSS entry, YT upload, etc.)                  │
#   │    - normalize → canonical story dict                             │
#   │    - enqueue story into RQ queue "sanitize"                       │
#   └───────────────────────────────────────────────────────────────────┘
#                                   │
#                                   ▼
#   ┌───────────────────────────────────────────────────────────────────┐
#   │  sanitizer (rq worker "sanitize")                                 │
#   │    - dedupe by semantic signature (title+summary)                 │
#   │    - first version of a "news event" wins                         │
#   │    - if ACCEPTED:                                                 │
#   │         * LPUSH story JSON into Redis FEED_KEY                    │
#   │         * LTRIM FEED_KEY to MAX_FEED_LEN                          │
#   │         * publish realtime fanout (pubsub + Redis stream)         │
#   │         * optionally enqueue push jobs → "push" (notifications)   │
#   │    - sanitizer is the ONLY writer to FEED_KEY                     │
#   └───────────────────────────────────────────────────────────────────┘
#                                   │
#                                   ▼
#   ┌───────────────────────────────────────────────────────────────────┐
#   │  api                                                              │
#   │    - pure read-only                                               │
#   │    - serves /v1/feed, /v1/story/{id}, /v1/search from Redis       │
#   │    - exposes /v1/realtime (SSE + WebSocket)                       │
#   └───────────────────────────────────────────────────────────────────┘
#
#   (optional)
#                                   │
#                                   ▼
#   ┌───────────────────────────────────────────────────────────────────┐
#   │  push (rq worker "push")                                          │
#   │    - consumes push jobs from sanitizer                            │
#   │    - finds device tokens per topic                               │
#   │    - builds notification payload                                 │
#   │    - (currently stub: print; can be wired to FCM/APNs later)      │
#   └───────────────────────────────────────────────────────────────────┘
#
# Redis:
#   - shared message bus (RQ queues: "events", "sanitize", "push")
#   - shared state (feed list, dedupe sets, rate limit counters, etc.)
#   - persisted via redis-data volume so restarts don't lose history.
# =============================================================================

x-env: &defaults
  ENV: prod
  TZ: Asia/Kolkata

  # Shared Redis URL
  REDIS_URL: redis://redis:6379/0

  # Public feed list key in Redis (only sanitizer mutates this)
  FEED_KEY: feed:items

  # Root source config.
  # NOTE: infra/source.yml itself references per-vertical files, e.g.:
  #   include_verticals:
  #     - verticals/entertainment.yml
  SOURCES_FILE: /app/infra/source.yml

  # External API keys consumed downstream (like TMDB in workers)
  TMDB_API_KEY: ${TMDB_API_KEY:-}

services:
  # --------------------------------------------------
  # REDIS (state + queues)
  # --------------------------------------------------
  redis:
    image: redis:7-alpine
    command:
      - redis-server
      - --save
      - ""
      - --appendonly
      - "yes"
    restart: unless-stopped
    volumes:
      - redis-data:/data
    ports:
      - "127.0.0.1:6379:6379"
    healthcheck:
      test: sh -c 'redis-cli ping | grep -q PONG'
      interval: 10s
      timeout: 3s
      retries: 5

  # --------------------------------------------------
  # SCHEDULER
  # --------------------------------------------------
  # Periodic ingestion scheduler:
  #   - reads infra/source.yml (which references vertical YAMLs)
  #   - merges all enabled channels + feeds from those verticals
  #   - enqueues poll work into RQ queue "events"
  scheduler:
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: scheduler
    restart: unless-stopped
    env_file: ../.env
    environment:
      <<: *defaults
    depends_on:
      redis:
        condition: service_healthy
    command:
      - python
      - -m
      - apps.scheduler.main
    read_only: true
    tmpfs:
      - /tmp
      - /var/tmp
    stop_grace_period: 10s

  # --------------------------------------------------
  # WEBHOOKS
  # --------------------------------------------------
  # HTTP-triggered ingestion:
  #   - YouTube PubSubHubbub callbacks
  #   - RSS WebSub callbacks
  #   - manual /subscribe endpoints
  #
  # On notify:
  #   - decides which channel/feed updated
  #   - enqueues fresh poll into "events" immediately
  webhooks:
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: webhooks
    restart: unless-stopped
    env_file: ../.env
    environment:
      <<: *defaults
    depends_on:
      redis:
        condition: service_healthy
    ports:
      - "127.0.0.1:18001:8000"
    command: >
      uvicorn apps.webhooks.main:app
      --host 0.0.0.0
      --port 8000
    read_only: true
    tmpfs:
      - /tmp
      - /var/tmp
    stop_grace_period: 10s

  # --------------------------------------------------
  # WORKERS
  # --------------------------------------------------
  # RQ worker for queue "events":
  #   - fetch raw source item (RSS entry, YT upload, etc.)
  #   - run normalize_event() to build canonical `story`
  #   - enqueue that story onto "sanitize"
  #
  # Workers DO NOT:
  #   - write to FEED_KEY
  #   - dedupe
  #   - send push
  workers:
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: worker
    restart: unless-stopped
    env_file: ../.env
    environment:
      <<: *defaults
      # rq also reads RQ_REDIS_URL
      RQ_REDIS_URL: redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy
    command: >
      sh -lc 'rq worker -u "${REDIS_URL:-redis://redis:6379/0}" events'
    read_only: true
    tmpfs:
      - /tmp
      - /var/tmp
    stop_grace_period: 10s

  # --------------------------------------------------
  # SANITIZER
  # --------------------------------------------------
  # RQ worker for queue "sanitize":
  #   - dedupes by story_signature(title+summary)
  #   - first story about an event wins forever
  #   - if accepted:
  #       * LPUSH into FEED_KEY
  #       * LTRIM feed length (MAX_FEED_LEN)
  #       * publish realtime fanout via Redis:
  #           - pub/sub channel FEED_PUBSUB
  #           - XADD into FEED_STREAM
  #       * OPTIONAL enqueue push job ("push" queue)
  #
  # ONLY sanitizer mutates FEED_KEY.
  sanitizer:
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: worker
    restart: unless-stopped
    env_file: ../.env
    environment:
      <<: *defaults

      # Dedup set of story signatures
      SEEN_KEY: feed:seen_signatures

      # Max feed list length retained in Redis
      MAX_FEED_LEN: "200"

      # Realtime fanout keys
      FEED_PUBSUB: feed:pub
      FEED_STREAM: feed:stream
      FEED_STREAM_MAXLEN: "5000"

      # Toggle this to "1" if you are running the push worker below
      ENABLE_PUSH_NOTIFICATIONS: "0"

      # rq connection
      RQ_REDIS_URL: redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy
    command: >
      sh -lc 'rq worker -u "${REDIS_URL:-redis://redis:6379/0}" sanitize'
    read_only: true
    tmpfs:
      - /tmp
      - /var/tmp
    stop_grace_period: 10s

  # --------------------------------------------------
  # PUSH (optional)
  # --------------------------------------------------
  # RQ worker for queue "push":
  #   - consumes jobs created by sanitizer (if ENABLE_PUSH_NOTIFICATIONS=1)
  #   - figures out which subscriber tokens to alert based on story.topics
  #   - builds push payload (title, summary snippet, thumb_url)
  #   - CURRENTLY logs to console (stub for FCM/APNs/etc.)
  #
  # If you don't want push right now:
  #   - leave this service commented out
  #   - keep ENABLE_PUSH_NOTIFICATIONS="0" in sanitizer
  #
  # push:
  #   build:
  #     context: ..
  #     dockerfile: infra/Dockerfile
  #     target: worker
  #   restart: unless-stopped
  #   env_file: ../.env
  #   environment:
  #     <<: *defaults
  #     RQ_REDIS_URL: redis://redis:6379/0
  #     PUSH_ENABLED: "1"
  #     PUSH_SET: "push:tokens"
  #     PUSH_META: "push:meta"
  #     PUSH_TOPIC_PREFIX: "push:topic:"
  #     PUSH_DEFAULT_TOPIC: "all"
  #     PUSH_MAX_TOKENS_PER_STORY: "5000"
  #     PUSH_BODY_MAX_CHARS: "180"
  #   depends_on:
  #     redis:
  #       condition: service_healthy
  #   command: >
  #     sh -lc 'rq worker -u "${REDIS_URL:-redis://redis:6379/0}" push'
  #   read_only: true
  #   tmpfs:
  #     - /tmp
  #     - /var/tmp
  #   stop_grace_period: 10s

  # --------------------------------------------------
  # API
  # --------------------------------------------------
  # Read-only/public API:
  #   - /v1/feed, /v1/story/{id}, /v1/search
  #   - /v1/realtime/stream (SSE)
  #   - /v1/realtime/ws     (WebSocket)
  #   - /v1/img?u=...       (image proxy)
  #
  # It never mutates feed data — only reads from Redis.
  api:
    build:
      context: ..
      dockerfile: infra/Dockerfile
      target: api
    restart: unless-stopped
    env_file: ../.env
    environment:
      <<: *defaults
    depends_on:
      redis:
        condition: service_healthy
      sanitizer:
        condition: service_started
    ports:
      - "127.0.0.1:18000:8000"
    command: >
      gunicorn -w 2 -k uvicorn.workers.UvicornWorker
      -b 0.0.0.0:8000 apps.api.app.main:app
    read_only: true
    tmpfs:
      - /tmp
      - /var/tmp
    stop_grace_period: 20s

volumes:
  redis-data: {}
